#!/usr/bin/env python3
"""
ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼
æ „é¤Šç‰¹æ€§ã€ãƒ†ã‚­ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿ã€ã‚«ãƒ†ã‚´ãƒªç‰¹æ€§ã‚’çµ±åˆ
"""

import numpy as np
from pathlib import Path
import json
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler

class MenuEncoder:
    """ãƒ¡ãƒ‹ãƒ¥ãƒ¼æƒ…å ±ã‚’å›ºå®šæ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›"""
    
    def __init__(self, menu_dir=None, vocab_size=50):
        self.menu_dir = Path(menu_dir or '/Users/onotakanori/Apps/kyowa-menu-optimizer/menus')
        self.vocab_size = vocab_size
        self.scaler = StandardScaler()
        self.tfidf = TfidfVectorizer(max_features=vocab_size, ngram_range=(1, 2))
        self.menu_cache = {}
        self.nutrition_keys = ['ã‚¨ãƒãƒ«ã‚®ãƒ¼(kcal)', 'ãŸã‚“ã±ãè³ª(g)', 'è„‚è³ª(g)', 'ç‚­æ°´åŒ–ç‰©(g)', 'ãƒ“ã‚¿ãƒŸãƒ³C(mg)']
        self.categories = {
            'meat': ['è‚‰', 'é¶', 'è±š', 'ç‰›', 'å”æš', 'ã‚¹ãƒ†ãƒ¼ã‚­'],
            'fish': ['é­š', 'ã•ã°', 'ã¾ãã‚', 'ã¶ã‚Š', 'ã‚µãƒ¼ãƒ¢ãƒ³', 'ã‚¨ãƒ“'],
            'vegetable': ['é‡èœ', 'ã‚µãƒ©ãƒ€', 'ãƒ–ãƒ­ãƒƒã‚³ãƒªãƒ¼', 'å¤§æ ¹', 'ã‚­ãƒ£ãƒ™ãƒ„', 'ã»ã†ã‚Œã‚“è‰'],
            'soup': ['æ±', 'ã‚¹ãƒ¼ãƒ—', 'ã¿ãæ±'],
            'rice': ['ã”é£¯', 'ãƒ©ã‚¤ã‚¹', 'ãƒãƒ£ãƒ¼ãƒãƒ³', 'ãƒ”ãƒ©ãƒ•'],
            'noodle': ['éºº', 'ã†ã©ã‚“', 'ãã°', 'ãƒ©ãƒ¼ãƒ¡ãƒ³', 'ãƒ‘ã‚¹ã‚¿'],
            'tofu': ['è±†è…', 'åšæšã’'],
            'egg': ['åµ', 'ç‰å­'],
            'fruit': ['æœå®Ÿ', 'ãƒ•ãƒ«ãƒ¼ãƒ„', 'ã¿ã‹ã‚“', 'ã‚¤ãƒã‚´'],
            'dessert': ['ãƒ‡ã‚¶ãƒ¼ãƒˆ', 'ã‚¢ã‚¤ã‚¹', 'ã‚±ãƒ¼ã‚­', 'ãƒ—ãƒ‡ã‚£ãƒ³ã‚°'],
            'mini': ['ãƒŸãƒ‹', 'å°'],
            'hot': ['æ¸©', 'ã‚ã¤ã‚ã¤'],
            'cold': ['å†·', 'ã²ã‚„ã²ã‚„'],
        }
        
    def load_all_menus(self, date=None):
        """å…¨ãƒ¡ãƒ‹ãƒ¥ãƒ¼ï¼ˆã¾ãŸã¯ç‰¹å®šæ—¥ä»˜ï¼‰ã‚’ãƒ­ãƒ¼ãƒ‰"""
        if date:
            menu_file = self.menu_dir / f'menus_{date}.json'
            with open(menu_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get('menus', [])
        
        all_menus = []
        for menu_file in sorted(self.menu_dir.glob('menus_*.json')):
            with open(menu_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                all_menus.extend(data.get('menus', []))
        
        return all_menus
    
    def extract_nutrition_features(self, menu_dict):
        """æ „é¤Šç‰¹æ€§ã‚’æŠ½å‡º (5æ¬¡å…ƒ)"""
        features = []
        for key in self.nutrition_keys:
            value = menu_dict.get('nutrition', {}).get(key, 0)
            if isinstance(value, str):
                try:
                    value = float(value)
                except:
                    value = 0
            features.append(float(value))
        return np.array(features)
    
    def extract_category_features(self, menu_name):
        """ã‚«ãƒ†ã‚´ãƒªç‰¹æ€§ã‚’æŠ½å‡º (13æ¬¡å…ƒ)"""
        features = []
        for cat_name, keywords in self.categories.items():
            score = any(kw in menu_name for kw in keywords)
            features.append(1.0 if score else 0.0)
        return np.array(features)
    
    def fit_text_encoder(self, menus):
        """ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’å­¦ç¿’"""
        menu_names = [m['name'] for m in menus]
        self.tfidf.fit(menu_names)
    
    def extract_text_features(self, menu_name):
        """ãƒ†ã‚­ã‚¹ãƒˆç‰¹æ€§ã‚’æŠ½å‡º (50æ¬¡å…ƒ, TF-IDF)"""
        if not hasattr(self.tfidf, 'vocabulary_'):
            return np.zeros(self.vocab_size)
        vec = self.tfidf.transform([menu_name]).toarray()[0]
        return vec
    
    def encode_menu(self, menu_dict):
        """ãƒ¡ãƒ‹ãƒ¥ãƒ¼å…¨ä½“ã‚’ç¬¦å·åŒ– (68æ¬¡å…ƒ: 5 nutrition + 50 text + 13 category)"""
        name = menu_dict.get('name', '')
        
        # å„ç‰¹æ€§ã‚’æŠ½å‡º
        nutrition = self.extract_nutrition_features(menu_dict)  # 5
        text = self.extract_text_features(name)                 # 50
        category = self.extract_category_features(name)         # 13
        
        # çµ±åˆ
        return np.concatenate([nutrition, text, category])
    
    def encode_menu_by_name(self, menu_name):
        """ãƒ¡ãƒ‹ãƒ¥ãƒ¼åã‹ã‚‰ç¬¦å·åŒ– (nutrition ã¯0åŸ‹ã‚)"""
        dummy_dict = {'name': menu_name, 'nutrition': {}}
        return self.encode_menu(dummy_dict)
    
    def encode_menus_batch(self, menu_dicts):
        """ãƒãƒƒãƒç¬¦å·åŒ–"""
        return np.array([self.encode_menu(m) for m in menu_dicts])
    
    def prepare_encoder(self, train_menus):
        """ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’åˆæœŸåŒ–ãƒ»å­¦ç¿’"""
        print(f"ğŸ“š ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’æº–å‚™ä¸­...")
        
        # ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’å­¦ç¿’
        self.fit_text_encoder(train_menus)
        
        # æ „é¤Šç‰¹æ€§ã®æ­£è¦åŒ–ç”¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã‚’å­¦ç¿’
        nutrition_features = np.array([self.extract_nutrition_features(m) for m in train_menus])
        if nutrition_features.shape[0] > 1:
            self.scaler.fit(nutrition_features)
        
        print(f"âœ… ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼æº–å‚™å®Œäº† ({len(train_menus)}ãƒ¡ãƒ‹ãƒ¥ãƒ¼å­¦ç¿’)")
        print(f"   - ãƒ†ã‚­ã‚¹ãƒˆèªå½™: {len(self.tfidf.vocabulary_)}å˜èª")
        print(f"   - å‡ºåŠ›æ¬¡å…ƒ: 68æ¬¡å…ƒ (æ „é¤Š5 + ãƒ†ã‚­ã‚¹ãƒˆ50 + ã‚«ãƒ†ã‚´ãƒª13)\n")

if __name__ == '__main__':
    encoder = MenuEncoder()
    menus = encoder.load_all_menus()
    encoder.prepare_encoder(menus)
    
    # ãƒ†ã‚¹ãƒˆ
    test_menu = {
        'name': 'è’¸ã—é¶&ãƒ–ãƒ­ãƒƒã‚³ãƒªãƒ¼',
        'nutrition': {
            'ã‚¨ãƒãƒ«ã‚®ãƒ¼(kcal)': '280',
            'ãŸã‚“ã±ãè³ª(g)': '28',
            'è„‚è³ª(g)': '12',
            'ç‚­æ°´åŒ–ç‰©(g)': '15',
            'ãƒ“ã‚¿ãƒŸãƒ³C(mg)': '45'
        }
    }
    
    encoded = encoder.encode_menu(test_menu)
    print(f"ãƒ†ã‚¹ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°: {encoded.shape} æ¬¡å…ƒ")
    print(f"å…ˆé ­10å€¤: {encoded[:10]}")
