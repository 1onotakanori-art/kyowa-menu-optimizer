#!/usr/bin/env python3
"""
A/B ãƒ†ã‚¹ãƒˆå®Ÿè£…
å¾“æ¥ãƒ¢ãƒ‡ãƒ«ã¨æ–°ãƒ¢ãƒ‡ãƒ«ã®æ¨å¥¨ã‚’æ¯”è¼ƒæ¤œè¨¼
"""

import json
import numpy as np
from pathlib import Path
from datetime import datetime
from collections import defaultdict
import sys

sys.path.insert(0, str(Path(__file__).parent))

class ABTestManager:
    """A/B ãƒ†ã‚¹ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, test_name, test_dir='ml/ab_tests'):
        self.test_name = test_name
        self.test_dir = Path(test_dir)
        self.test_dir.mkdir(parents=True, exist_ok=True)
        self.test_file = self.test_dir / f'{test_name}.json'
        self.test_data = self._load_test_data()
    
    def _load_test_data(self):
        """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰"""
        if self.test_file.exists():
            with open(self.test_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        
        return {
            'test_name': self.test_name,
            'created_at': datetime.now().isoformat(),
            'control': {
                'model_type': 'RandomForest (å€‹åˆ¥ãƒ¡ãƒ‹ãƒ¥ãƒ¼äºˆæ¸¬)',
                'recommendations': [],
                'user_feedback': []
            },
            'treatment': {
                'model_type': 'Seq2Set Transformer + æ „é¤Šåˆ¶ç´„',
                'recommendations': [],
                'user_feedback': []
            },
            'metrics': {}
        }
    
    def record_recommendation(self, group, date, menus, explanation=''):
        """æ¨å¥¨ã‚’è¨˜éŒ²"""
        if group not in ['control', 'treatment']:
            raise ValueError('group ã¯ control ã¾ãŸã¯ treatment ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™')
        
        recommendation = {
            'date': date,
            'timestamp': datetime.now().isoformat(),
            'menus': menus,
            'explanation': explanation
        }
        
        self.test_data[group]['recommendations'].append(recommendation)
        self._save_test_data()
        
        return {
            'group': group,
            'recommendation_id': len(self.test_data[group]['recommendations']) - 1,
            'recorded_at': datetime.now().isoformat()
        }
    
    def record_feedback(self, group, recommendation_id, feedback):
        """ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è¨˜éŒ²"""
        if group not in ['control', 'treatment']:
            raise ValueError('group ã¯ control ã¾ãŸã¯ treatment ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™')
        
        # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å½¢å¼: {'satisfaction': 1-5, 'adoption': True/False, 'comments': '...'}
        feedback_entry = {
            'recommendation_id': recommendation_id,
            'timestamp': datetime.now().isoformat(),
            'data': feedback
        }
        
        self.test_data[group]['user_feedback'].append(feedback_entry)
        self._save_test_data()
        
        return {
            'feedback_id': len(self.test_data[group]['user_feedback']) - 1,
            'recorded_at': datetime.now().isoformat()
        }
    
    def calculate_metrics(self):
        """ãƒ†ã‚¹ãƒˆãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—"""
        metrics = {}
        
        for group in ['control', 'treatment']:
            feedback = self.test_data[group]['user_feedback']
            
            if not feedback:
                metrics[group] = {
                    'sample_size': 0,
                    'satisfaction': None,
                    'adoption_rate': None
                }
                continue
            
            satisfactions = [f['data']['satisfaction'] for f in feedback]
            adoptions = [f['data']['adoption'] for f in feedback]
            
            metrics[group] = {
                'sample_size': len(feedback),
                'satisfaction': {
                    'mean': np.mean(satisfactions),
                    'std': np.std(satisfactions),
                    'min': np.min(satisfactions),
                    'max': np.max(satisfactions)
                },
                'adoption_rate': np.mean(adoptions),
                'adoption_count': sum(adoptions),
                'rejection_count': len(adoptions) - sum(adoptions)
            }
        
        self.test_data['metrics'] = metrics
        self._save_test_data()
        
        return metrics
    
    def calculate_statistical_significance(self, alpha=0.05):
        """çµ±è¨ˆçš„æœ‰æ„æ€§ã‚’è¨ˆç®— (t-test)"""
        from scipy import stats
        
        control_feedback = self.test_data['control']['user_feedback']
        treatment_feedback = self.test_data['treatment']['user_feedback']
        
        if not control_feedback or not treatment_feedback:
            return {
                'status': 'insufficient_data',
                'reason': 'ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ç¾¤ã¾ãŸã¯ãƒˆãƒªãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆç¾¤ã®ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™'
            }
        
        control_sats = [f['data']['satisfaction'] for f in control_feedback]
        treatment_sats = [f['data']['satisfaction'] for f in treatment_feedback]
        
        t_stat, p_value = stats.ttest_ind(control_sats, treatment_sats)
        
        is_significant = p_value < alpha
        
        return {
            'p_value': p_value,
            'alpha': alpha,
            'is_significant': is_significant,
            'interpretation': (
                'ãƒˆãƒªãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆç¾¤ãŒæœ‰æ„ã«å„ªã‚Œã¦ã„ã¾ã™' if is_significant and np.mean(treatment_sats) > np.mean(control_sats)
                else 'ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ç¾¤ãŒæœ‰æ„ã«å„ªã‚Œã¦ã„ã¾ã™' if is_significant and np.mean(control_sats) > np.mean(treatment_sats)
                else 'æœ‰æ„ãªå·®ãŒã‚ã‚Šã¾ã›ã‚“'
            )
        }
    
    def generate_report(self):
        """ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        metrics = self.calculate_metrics()
        
        report = {
            'test_name': self.test_name,
            'start_date': self.test_data['created_at'],
            'end_date': datetime.now().isoformat(),
            'control_model': self.test_data['control']['model_type'],
            'treatment_model': self.test_data['treatment']['model_type'],
            'metrics': metrics,
            'statistical_significance': self.calculate_statistical_significance()
        }
        
        return report
    
    def print_report(self):
        """ãƒ¬ãƒãƒ¼ãƒˆã‚’è¡¨ç¤º"""
        report = self.generate_report()
        metrics = report['metrics']
        
        print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                 ğŸ“Š A/B ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆ                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ã€ãƒ†ã‚¹ãƒˆæ¦‚è¦ã€‘
  ãƒ†ã‚¹ãƒˆå: {report['test_name']}
  é–‹å§‹æ—¥: {report['start_date']}
  çµ‚äº†æ—¥: {report['end_date']}

ã€ã‚°ãƒ«ãƒ¼ãƒ—è¨­å®šã€‘
  ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ« (æ—¢å­˜): {report['control_model']}
  ãƒˆãƒªãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆ (æ–°): {report['treatment_model']}

ã€æº€è¶³åº¦ã‚¹ã‚³ã‚¢ (1-5)ã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
""")
        
        for group in ['control', 'treatment']:
            m = metrics[group]
            if m['sample_size'] == 0:
                print(f"{group}: ãƒ‡ãƒ¼ã‚¿ãªã—")
                continue
            
            sat = m['satisfaction']
            print(f"""
{group.upper()}:
  ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º: {m['sample_size']}
  å¹³å‡æº€è¶³åº¦: {sat['mean']:.2f} / 5.0 (Ïƒ={sat['std']:.2f})
  ç¯„å›²: {sat['min']:.0f} ~ {sat['max']:.0f}
  æ¡æŠç‡: {m['adoption_rate']:.1%} ({m['adoption_count']}æ¡æŠ / {m['rejection_count']}æ‹’å¦)
""")
        
        sig = report['statistical_significance']
        print(f"""
ã€çµ±è¨ˆçš„æ¤œå®š (ç‹¬ç«‹tæ¤œå®š)ã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  På€¤: {sig['p_value']:.4f} (æœ‰æ„æ°´æº–: {sig['alpha']})
  çµè«–: {sig['interpretation']}
  {'âœ… æœ‰æ„å·®ã‚ã‚Š' if sig['is_significant'] else 'âš ï¸ æœ‰æ„å·®ãªã—'}
""")
    
    def _save_test_data(self):
        """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        with open(self.test_file, 'w', encoding='utf-8') as f:
            json.dump(self.test_data, f, ensure_ascii=False, indent=2)
    
    def export_results(self, output_path):
        """çµæœã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        report = self.generate_report()
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        return output_path

def demo_ab_test():
    """ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘               ğŸ§ª A/B ãƒ†ã‚¹ãƒˆå®Ÿè£… - ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ã€A/B ãƒ†ã‚¹ãƒˆã®ç›®çš„ã€‘

  å¾“æ¥ãƒ¢ãƒ‡ãƒ« (ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«):
    RandomForest ã«ã‚ˆã‚‹å€‹åˆ¥ãƒ¡ãƒ‹ãƒ¥ãƒ¼äºˆæ¸¬
    â””â”€ ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³

  æ–°ãƒ¢ãƒ‡ãƒ« (ãƒˆãƒªãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆ):
    Seq2Set Transformer + æ „é¤Šåˆ¶ç´„
    â””â”€ æ”¹å–„ç‰ˆ

ã€ãƒ†ã‚¹ãƒˆæŒ‡æ¨™ã€‘

  1. æº€è¶³åº¦ã‚¹ã‚³ã‚¢ (1-5 â˜…)
     â””â”€ ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ¨å¥¨ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã«ã©ã‚Œã»ã©æº€è¶³ã—ãŸã‹

  2. æ¡æŠç‡ (%)
     â””â”€ ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ¨å¥¨ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’å®Ÿéš›ã«é¸æŠã—ãŸå‰²åˆ

  3. èª¬æ˜ç†è§£åº¦ (1-5 â˜…)
     â””â”€ æ¨å¥¨ç†ç”±ã‚’ã©ã‚Œã»ã©ç†è§£ã§ããŸã‹

ã€ä½¿ç”¨ä¾‹ã€‘

1. A/B ãƒ†ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’åˆæœŸåŒ–
   ab_test = ABTestManager('seq2set_vs_rf_test_v1')

2. æ¨å¥¨ã‚’è¨˜éŒ²
   ab_test.record_recommendation(
     'control',
     '2026-02-01',
     ['è’¸ã—é¶&ãƒ–ãƒ­ãƒƒã‚³ãƒªãƒ¼', 'ç™½èœã¨ãƒ„ãƒŠã®ã•ã£ã¨ç…®'],
     'RFæ¨å¥¨'
   )

3. ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è¨˜éŒ²
   ab_test.record_feedback(
     'control',
     recommendation_id=0,
     feedback={
       'satisfaction': 4,
       'adoption': True,
       'comments': 'ã‚¿ãƒ³ãƒ‘ã‚¯è³ªãŒå¤šãã¦è‰¯ã„'
     }
   )

4. ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
   ab_test.print_report()
   ab_test.export_results('ml/ab_tests/results.json')

ã€æœŸå¾…ã•ã‚Œã‚‹çµæœã€‘

  æº€è¶³åº¦ã‚¹ã‚³ã‚¢:
    ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«: å¹³å‡ 3.2 / 5.0
    ãƒˆãƒªãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆ: å¹³å‡ 3.8 / 5.0
    æ”¹å–„ç‡: +18.75%

  æ¡æŠç‡:
    ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«: 65%
    ãƒˆãƒªãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆ: 78%
    æ”¹å–„ç‡: +20%

ã€çµ±è¨ˆçš„æœ‰æ„æ€§ã€‘

  på€¤ < 0.05: 95%ã®ä¿¡é ¼åº¦ã§å·®ãŒã‚ã‚‹
  çµè«–: æ–°ãƒ¢ãƒ‡ãƒ«ãŒå„ªã‚Œã¦ã„ã‚‹ã“ã¨ãŒçµ±è¨ˆçš„ã«è¨¼æ˜ã•ã‚Œã‚‹

ã€ãƒ‡ãƒ¼ã‚¿ä¿å­˜ã€‘

~/.../ml/ab_tests/
â”œâ”€â”€ seq2set_vs_rf_test_v1.json
â”œâ”€â”€ seq2set_vs_rf_test_v2.json
â””â”€â”€ results.json

ã€æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã€‘

  1. æœ¬ç•ªç’°å¢ƒã§ãƒªã‚¢ãƒ«ãƒ¦ãƒ¼ã‚¶ãƒ¼ã§å®Ÿæ–½ (æœ€ä½30ã‚µãƒ³ãƒ—ãƒ«/ã‚°ãƒ«ãƒ¼ãƒ—)
  2. é€±å˜ä½ã§ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ç›£è¦–
  3. çµ±è¨ˆçš„æœ‰æ„æ€§ã‚’ç¢ºèªå¾Œã€æ–°ãƒ¢ãƒ‡ãƒ«ã¸å®Œå…¨ç§»è¡Œ
  4. ç¶™ç¶šçš„ãªæ”¹å–„ã‚µã‚¤ã‚¯ãƒ«

""")

if __name__ == '__main__':
    demo_ab_test()
