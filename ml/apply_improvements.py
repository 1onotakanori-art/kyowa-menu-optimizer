#!/usr/bin/env python3
"""
æ”¹å–„ã•ã‚ŒãŸãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å…¨æ—¥ä»˜ã«é©ç”¨
æ—¢å­˜ã® ai-selections JSON ã«è¤‡åˆã‚¹ã‚³ã‚¢æƒ…å ±ã‚’è¿½åŠ 
"""

import json
import torch
import numpy as np
from pathlib import Path
import sys
from datetime import datetime

sys.path.insert(0, str(Path(__file__).parent))
from menu_encoder import MenuEncoder
from seq2set_transformer import Seq2SetTransformer
from improve_recommendations import (
    DiversityScorer,
    NutritionMatcher,
    AllergenFilter,
    RecommendationImprover
)


def apply_improvements_to_all_dates(
    diversity_weight=0.20,
    nutrition_weight=0.30,
    model_weight=0.50
):
    """
    å…¨æ—¥ä»˜ã®AIæ¨å¥¨ã«æ”¹å–„ã‚’é©ç”¨
    """
    improver = RecommendationImprover()
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰
    print("ğŸ“š ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
    all_menus, menu_to_idx, idx_to_menu, _ = improver.load_data()
    
    # AIæ¨å¥¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰åˆ©ç”¨å¯èƒ½æ—¥ä»˜ã‚’å–å¾—
    ai_dir = Path(__file__).parent.parent / 'docs' / 'ai-selections'
    index_path = ai_dir / 'available-ai-dates.json'
    
    with open(index_path, 'r', encoding='utf-8') as f:
        index_data = json.load(f)
    
    dates = index_data.get('dates', [])
    print(f"\nğŸ”„ {len(dates)}å€‹ã®æ—¥ä»˜ã‚’å‡¦ç†ä¸­...\n")
    
    improvement_stats = {
        'total_dates': len(dates),
        'processed': 0,
        'errors': 0,
        'total_score_improvement': 0,
        'avg_diversity_score': [],
        'avg_nutrition_score': [],
        'avg_composite_score': []
    }
    
    # å„æ—¥ä»˜ã®æ¨å¥¨ã‚’æ”¹å–„
    for date in dates:
        try:
            ai_path = ai_dir / f'ai-selections_{date}.json'
            
            with open(ai_path, 'r', encoding='utf-8') as f:
                ai_data = json.load(f)
            
            # å…ƒã€…ã®æ¨å¥¨
            original_recs = ai_data.get('recommendations', [])
            
            # æ”¹å–„ã‚’é©ç”¨
            improved_recs = improver.generate_improved_recommendations(
                original_recs,
                all_menus,
                idx_to_menu,
                diversity_weight=diversity_weight,
                nutrition_weight=nutrition_weight,
                model_weight=model_weight,
                exclude_allergens=[]
            )
            
            # æ”¹å–„æ¸ˆã¿ã‚¹ã‚³ã‚¢æƒ…å ±ã‚’è¿½åŠ 
            for i, rec in enumerate(improved_recs):
                original_recs[i]['composite_score'] = rec['composite_score']
                original_recs[i]['model_score'] = rec['model_score']
                original_recs[i]['diversity_score'] = rec['diversity_score']
                original_recs[i]['nutrition_match_score'] = rec['nutrition_match_score']
                original_recs[i]['score_improvement'] = (
                    rec['composite_score'] - rec['model_score']
                ) if rec['model_score'] > 0 else 0
            
            # çµ±è¨ˆã‚’æ›´æ–°
            avg_diversity = np.mean([r['diversity_score'] for r in improved_recs])
            avg_nutrition = np.mean([r['nutrition_match_score'] for r in improved_recs])
            avg_composite = np.mean([r['composite_score'] for r in improved_recs])
            
            improvement_stats['avg_diversity_score'].append(avg_diversity)
            improvement_stats['avg_nutrition_score'].append(avg_nutrition)
            improvement_stats['avg_composite_score'].append(avg_composite)
            
            # æ”¹å–„æ¸ˆã¿JSONã‚’ä¿å­˜
            ai_data['recommendations'] = original_recs
            ai_data['improvement_applied'] = True
            ai_data['improvement_config'] = {
                'diversity_weight': diversity_weight,
                'nutrition_weight': nutrition_weight,
                'model_weight': model_weight,
                'applied_at': datetime.now().isoformat()
            }
            ai_data['improvement_stats'] = {
                'avg_diversity_score': float(avg_diversity),
                'avg_nutrition_match_score': float(avg_nutrition),
                'avg_composite_score': float(avg_composite)
            }
            
            with open(ai_path, 'w', encoding='utf-8') as f:
                json.dump(ai_data, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… {date}: å¤šæ§˜æ€§{avg_diversity:.3f} | æ „é¤Š{avg_nutrition:.3f} | è¤‡åˆ{avg_composite:.3f}")
            improvement_stats['processed'] += 1
            
        except Exception as e:
            print(f"âŒ {date}: ã‚¨ãƒ©ãƒ¼ - {str(e)}")
            improvement_stats['errors'] += 1
    
    # çµ±è¨ˆãƒ¬ãƒãƒ¼ãƒˆ
    print("\n" + "="*70)
    print("ğŸ“Š æ”¹å–„é©ç”¨ãƒ¬ãƒãƒ¼ãƒˆ")
    print("="*70)
    print(f"\nâœ… å‡¦ç†å®Œäº†: {improvement_stats['processed']}/{improvement_stats['total_dates']}å€‹")
    print(f"âŒ ã‚¨ãƒ©ãƒ¼: {improvement_stats['errors']}å€‹")
    
    if improvement_stats['avg_diversity_score']:
        print(f"\nğŸ“ˆ å…¨æ—¥ä»˜ã®å¹³å‡çµ±è¨ˆ:")
        print(f"  å¤šæ§˜æ€§ã‚¹ã‚³ã‚¢å¹³å‡: {np.mean(improvement_stats['avg_diversity_score']):.4f}")
        print(f"  æ „é¤Šãƒãƒƒãƒå¹³å‡: {np.mean(improvement_stats['avg_nutrition_score']):.4f}")
        print(f"  è¤‡åˆã‚¹ã‚³ã‚¢å¹³å‡: {np.mean(improvement_stats['avg_composite_score']):.4f}")
    
    print("\n" + "="*70)
    print(f"âœ… æ”¹å–„æ¸ˆã¿AIæ¨å¥¨ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {ai_dir}")
    print("="*70 + "\n")


if __name__ == '__main__':
    apply_improvements_to_all_dates(
        diversity_weight=0.20,
        nutrition_weight=0.30,
        model_weight=0.50
    )
